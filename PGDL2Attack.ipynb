{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWFxHJB-R3hh",
        "outputId": "a8ef71f8-e95e-4921-d24d-5fc9a1bd074e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.8/dist-packages (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Displays a progress bar\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
        "!pip install torchattacks\n",
        "import torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and train, val, test splits\n",
        "print(\"Loading datasets...\")\n",
        "my_transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "MNIST_train = datasets.MNIST('.', download=True, train=True, transform=my_transformer)\n",
        "MNIST_test = datasets.MNIST('.', download=True, train=False, transform=my_transformer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUsltUk0a_sG",
        "outputId": "c29c31c6-4a33-46fd-e3f3-65b54f25e345"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "trainloader = DataLoader(MNIST_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(MNIST_test, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "PpKnQMczbBEm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),                                            \n",
        "            nn.MaxPool2d(kernel_size=2),   \n",
        "            nn.ReLU(),         \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),                        \n",
        "            nn.MaxPool2d(2),   \n",
        "            nn.ReLU(),                \n",
        "        )\n",
        "        self.out = nn.Linear(1152, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "nHDdXENzbCiY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
        "model = Network()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/bestModelUpdated.pt'))\n",
        "\n",
        "# take the perturbations and make a fresh model:\n",
        "attackedModel = Network().to(device)\n",
        "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
        "optimizer = optim.AdamW(attackedModel.parameters(), lr=0.001)\n",
        "num_epoch = 5 \n"
      ],
      "metadata": {
        "id": "_3LDJWPtbJLR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(attackedModel, x_batch, y_batch):\n",
        "        \"\"\" Performs a step during training. \"\"\"\n",
        "        # Compute output for example\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients from the previous iteration\n",
        "        pred = attackedModel(x_batch.cuda()) # This will call Network.forward() that you implement\n",
        "        loss = criterion(pred, y_batch) # Calculate the loss\n",
        "        loss.backward() # Backprop gradients to all tensors in the network\n",
        "        optimizer.step() # Update trainable weights\n",
        "        optimizer.zero_grad()\n",
        "        "
      ],
      "metadata": {
        "id": "qQQkwgQ3n3J2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = torchattacks.PGDL2(model, eps=1.0, alpha=0.2, steps=10, random_start=True)\n",
        "num_samples = 0\n",
        "correct_prediction = 0\n",
        "perturbations=[]\n",
        "labels=[]\n",
        "for image, target_label in testloader:\n",
        "  adv_images = attack(image, target_label)\n",
        "  # print(type(image))\n",
        "  # print(type(adv_images))\n",
        "  #maybe introduce training here\n",
        "  output = model(adv_images)\n",
        "  finalPred = torch.argmax(output,dim=1)\n",
        "  #check how many samples were predicted right\n",
        "  correct_prediction += (finalPred.cuda() == target_label.cuda()).sum().item()\n",
        "  num_samples += BATCH_SIZE \n",
        "  # adv_images=adv_images.to(device)\n",
        "  # target_label=target_label.to(device)\n",
        "  #train_step(attackedModel, adv_images, target_label)\n",
        "  # perturbations.append(adv_images)\n",
        "  # labels.append(target_label)\n",
        "\n",
        "print(\"Number of Correct Predictions: \" + str(correct_prediction))\n",
        "print(\"Total Number of Samples: \" + str(num_samples))\n",
        "print()\n",
        "accuracy = float(correct_prediction) / num_samples\n",
        "print('Model Robust Accuracy: {:.3f}％'.format(accuracy * 100))\n",
        "print('Successful Attack Accuracy: {:.3f}％'.format(100 - (accuracy * 100)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOzTOaaAbQYM",
        "outputId": "c562a80d-28ab-4e87-f381-c7911c8aa408"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Correct Predictions: 7910\n",
            "Total Number of Samples: 10000\n",
            "\n",
            "Model Robust Accuracy: 79.100％\n",
            "Successful Attack Accuracy: 20.900％\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image, target_label in trainloader:\n",
        "  adv_images = attack(image, target_label)\n",
        "  # print(type(image))\n",
        "  # print(type(adv_images))\n",
        "  #maybe introduce training here\n",
        "  output = model(adv_images)\n",
        "  finalPred = torch.argmax(output,dim=1)\n",
        "  #check how many samples were predicted right\n",
        "  correct_prediction += (finalPred == target_label).sum().item()\n",
        "  num_samples += BATCH_SIZE \n",
        "  adv_images=adv_images.to(device)\n",
        "  target_label=target_label.to(device)\n",
        "  train_step(attackedModel, adv_images, target_label)\n",
        "  train_step(attackedModel, image, target_label)\n"
      ],
      "metadata": {
        "id": "yDsupzko9LDD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take the perturbations and make a fresh model:\n",
        "def evaluate(model, loader): # Evaluate accuracy on validation / test set\n",
        "    running_loss = []\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    with torch.no_grad(): # Do not calculate grident to speed up computation\n",
        "        for batch, label in tqdm(loader):\n",
        "            batch = batch.to(device)\n",
        "            label = label.to(device)\n",
        "            pred = model(batch)\n",
        "            loss = criterion(pred, label) # Calculate the loss\n",
        "            running_loss.append(loss.item())\n",
        "            correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
        "    acc = correct/len(loader.dataset)\n",
        "    print(\"Evaluation accuracy: {}\".format(acc))\n",
        "    return acc, np.mean(running_loss)\n",
        "\n",
        "# #run training and validation for training. \n",
        "# training_loss = train(model, trainloader, 5)\n",
        "\n",
        "\n",
        "\n",
        "# #save the model\n",
        "torch.save(attackedModel.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/bestModel_PGDl2.pt\")\n",
        "\n",
        "#train the  model on the original training data as well\n",
        "\n",
        "print(\"Evaluate on test set with only original examples on loaded model\")\n",
        "evaluate(model.cuda(), testloader)\n",
        "\n",
        "print(\"Evaluate on test set with adversarial examples\")\n",
        "evaluate(attackedModel, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhEuSREeeuXw",
        "outputId": "7fb0c7e7-c10b-46f8-9a31-df638e13e48c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test set with only original examples on loaded model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 102.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 0.9901\n",
            "Evaluate on test set with adversarial examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 97.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 0.9809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9809, 0.057488766357419084)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}