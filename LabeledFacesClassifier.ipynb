{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from tqdm import tqdm # Displays a progress bar"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import nn\n", "from torch import optim\n", "import torch.nn.functional as F\n", "from torchvision import datasets, transforms\n", "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n", "from torch.autograd import Variable\n", "import random\n", "import torchattacks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transformer = transforms.Compose([\n", "    transforms.ToTensor(), # Transform from [0,255] uint8 to [0,1] float\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lfw_dataset = datasets.LFWPeople('.', download=True, transform=transformer)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dataset LFWPeople<br>\n", "    Number of datapoints: 13233<br>\n", "    Root location: .\\lfw-py<br>\n", "    Alignment: funneled<br>\n", "    Split: 10fold<br>\n", "    Classes (identities): 5749"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data, test_data = random_split(lfw_dataset, [10586, 2647])\n", "BATCH_SIZE = 100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n", "testloader = DataLoader(test_data, batch_size=BATCH_SIZE)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "#from deepface.commons import functions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.convLayer1 = nn.Sequential(\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(3, 64, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(64, 64, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d((2, 2), stride=(2, 2))\n", "        )\n", "        self.convLayer2 = nn.Sequential(\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(64, 128, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(128, 128, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d((2, 2), stride=(2, 2)) \n", "        )\n", "        self.convLayer3 = nn.Sequential(\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(128, 256, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(256, 256, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(256, 256, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d((2, 2), stride=(2, 2))\n", "        )\n", "        self.convLayer4 = nn.Sequential(\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(256, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(512, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(512, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d((2, 2), stride=(2, 2))\n", "        )\n", "        self.convLayer5 = nn.Sequential(\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(512, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(512, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.ZeroPad2d((1, 1)),\n", "            nn.Conv2d(512, 512, (3, 3)),\n", "            nn.ReLU(),\n", "            nn.MaxPool2d((2, 2), stride=(2, 2))\n", "        )\n", "        self.convLayer6 = nn.Sequential(\n", "            nn.Conv2d(512, 4096, (2, 7)),\n", "            nn.Dropout(p=0.5),\n", "            nn.Conv2d(4096, 4096, (1, 1)),\n", "            nn.Dropout(p=0.5),\n", "            nn.Conv2d(4096, 2622, (1, 1)),\n", "            nn.Flatten(),\n", "            nn.Softmax(dim=1)\n", "        )\n", "    def forward(self, x):\n", "        x = self.convLayer1(x)\n", "        x = self.convLayer2(x)\n", "        x = self.convLayer3(x)\n", "        x = self.convLayer4(x)\n", "        x = self.convLayer5(x)\n", "        x = self.convLayer6(x)\n", "        return x\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n", "model = Network().to(device)\n", "# TODO: Define loss function \n", "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n", "# TODO: Modify the line below, experiment with different optimizers and parameters (such as learning rate)\n", "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n", "num_epoch = 5 # TODO: Choose an appropriate number of training epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(model, train_loader, num_epoch = 5): # Train the model\n", "    training_loss = []\n", "    #validation_loss = []\n", "    print(\"Start training...\")\n", "    model.train() # Set the model to training mode\n", "    for i in range(num_epoch):\n", "        training_running_loss = []\n", "        for batch, label in tqdm(train_loader):\n", "            batch = batch.to(device)\n", "            label = label.to(device)\n", "            optimizer.zero_grad() # Clear gradients from the previous iteration\n", "            pred = model(batch) # This will call Network.forward() that you implement\n", "            loss = criterion(pred, label) # Calculate the loss\n", "            training_running_loss.append(loss.item())\n", "            loss.backward() # Backprop gradients to all tensors in the network\n", "            optimizer.step() # Update trainable weights\n", "        print(\"Epoch {} loss:{}\".format(i+1,np.mean(training_running_loss))) # Print the average loss for this epoch\n", "        training_loss.append(np.mean(training_running_loss))\n\n", "        #calculate the validation loss by setting model to evaluation mode\n", "        # validation_accuracy, val_loss = evaluate(model, val_loader)\n", "        # validation_loss.append(val_loss)\n", "    print(\"Done!\")\n", "    return training_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate(model, loader): # Evaluate accuracy on validation / test set\n", "    running_loss = []\n", "    model.eval() # Set the model to evaluation mode\n", "    correct = 0\n", "    with torch.no_grad(): # Do not calculate grident to speed up computation\n", "        for batch, label in tqdm(loader):\n", "            batch = batch.to(device)\n", "            label = label.to(device)\n", "            pred = model(batch)\n", "            loss = criterion(pred, label) # Calculate the loss\n", "            running_loss.append(loss.item())\n", "            correct += (torch.argmax(pred,dim=1)==label).sum().item()\n", "    acc = correct/len(loader.dataset)\n", "    print(\"Evaluation accuracy: {}\".format(acc))\n", "    return acc, np.mean(running_loss)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["un training and validation for training. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_loss = train(model, trainloader, 5)\n", "#save the model\n", "torch.save(model.state_dict(), \"bestModel.pt\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Evaluate on test set\")\n", "evaluate(model, testloader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#plot the validation and training loss<br>\n", "epochs = [1, 2, 3, 4, 5]<br>\n", "plt.plot(epochs, training_loss, label='train_loss')<br>\n", "plt.plot(epochs, validation_loss, label='val_loss')<br>\n", "plt.xlabel(\"Epoch\")<br>\n", "plt.ylabel(\"Loss\")<br>\n", "plt.legend()<br>\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["define loss function, optimizer and number of epochs<br>\n", "train and test to get baseline accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.pgd<br>\n", "Pick attacks here, easy to execute them"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}